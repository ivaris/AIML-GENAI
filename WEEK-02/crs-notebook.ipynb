{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmKLmjqmHMQM"
      },
      "source": [
        "<center><p float=\"center\">\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e9/4_RGB_McCombs_School_Brand_Branded.png\" width=\"300\" height=\"100\"/>\n",
        "  <img src=\"https://mma.prnewswire.com/media/1458111/Great_Learning_Logo.jpg?p=facebook\" width=\"200\" height=\"100\"/>\n",
        "</p></center>\n",
        "\n",
        "<center><font size=10>Generative AI for Business Applications</center></font>\n",
        "<center><font size=6>Agentic AI Workflows - Week 2</center></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azxWym9-HMpz"
      },
      "source": [
        "<center><p float=\"center\">\n",
        "  <img src=\"https://images.pexels.com/photos/33910465/pexels-photo-33910465.jpeg\" width=720></a>\n",
        "<center><font size=6>Greatglobe Logistics Assistant: Automating Product Compliance and Customs Guidance</center></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keS00aIfPsKA"
      },
      "source": [
        "#**Problem Statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSy2Fcr4CGwQ"
      },
      "source": [
        "## Business Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tblxSSyiCGwQ"
      },
      "source": [
        "Greatglobe Logistics is a global supply chain company that manages the shipment of more than 500 products for 20-30 client companies across multiple domains. Each shipment may require compliance with international trade regulations, including import/export documentation, customs duties, and payment procedures. For logistics managers and supply chain teams, gathering accurate documentation and understanding payment obligations for each shipment is time-consuming and prone to errors. Automating this process using data and intelligent agents can greatly improve operational efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzNRW3RuCGwS"
      },
      "source": [
        "Currently, retrieving product details and corresponding trade compliance requirements is a manual, fragmented process:\n",
        "\n",
        "- Product information is stored in internal databases (Product_ID, category, cost, etc.).\n",
        "- Compliance information such as required import/export documents, duty payment methods, and obligations must be researched online, which is slow and inconsistent.\n",
        "\n",
        "This makes it difficult for logistics teams to quickly verify shipments, especially when handling multiple clients across different countries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MjoqrkPCGwT"
      },
      "source": [
        "##  Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETPuZvM2CGwU"
      },
      "source": [
        "The goal of this project is to build an interactive logistics assistant that:\n",
        "\n",
        "- Retrieves product details from a SQL database based on a user-provided Product_ID.\n",
        "- Uses a web agent to fetch up-to-date import/export documents and payment methods for the productâ€™s HS/HSN code, based on source and destination countries.\n",
        "- Presents the information in a structured format, highlighting both required documentation and any additional compliance information if available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a_DZ5yJCGwV"
      },
      "source": [
        "## Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEzFA3SWCGwW"
      },
      "source": [
        "The database contains product-level information that includes:\n",
        "\n",
        "- Product_ID - Unique identifier for each product.\n",
        "- Product_Name - Name of the product.\n",
        "- Category - Broad classification of the product (e.g., Electronics, Textiles, Pharmaceuticals).\n",
        "- HSN_Code - Harmonized System of Nomenclature code for customs classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyAYFkGZM2bV"
      },
      "source": [
        "#**Installing and Importing Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "548b20a8",
        "outputId": "aad3c756-3fd4-448e-fae3-ad2f67d8fb66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: openai in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (1.109.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: tqdm>4 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: certifi in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: psycopg2-binary in /Users/rvavi3/Library/Python/3.9/lib/python/site-packages (2.9.11)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q tavily-python==0.7.12 \\\n",
        "                langchain-community==0.3.29 langchain-openai==0.3.30 \n",
        "%pip install openai\n",
        "%pip install pandas\n",
        "%pip install psycopg2-binary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXmpt2EluGxV"
      },
      "source": [
        "**Note:**\n",
        "\n",
        "- After running the above cell, kindly restart the runtime (for Google Colab) or notebook kernel (for Jupyter Notebook), and run all cells sequentially from the next cell.\n",
        "- On executing the above line of code, you might see a warning regarding package dependencies. This error message can be ignored as the above code ensures that all necessary libraries and their dependencies are maintained to successfully execute the code in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fu8MNH13CGwX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/rvavi3/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import sqlite3                                                       #Imports Pythonâ€™s built-in SQLite library to create and interact with SQLite databases.\n",
        "#import pandas as pd                                                  #Imports Pandas for data manipulation and reading CSV files.\n",
        "from openai import OpenAI                                            #Imports OpenAI for parsing search results (Optional)\n",
        "import json                                                          #Imports Json for handling search results\n",
        "import os\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import Tool\n",
        "from tavily import TavilyClient                                      #Tavily Search API, which performs real-time web searches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fUZrhkJIGsnu"
      },
      "outputs": [],
      "source": [
        "# Load the JSON file and extract values\n",
        "file_name = 'config.json'\n",
        "with open(file_name, 'r') as file:\n",
        "    config = json.load(file)\n",
        "    OPENAI_API_KEY = config.get(\"OPENAI_API_KEY\") # Loading the API Key\n",
        "    OPENAI_API_BASE = config.get(\"OPENAI_API_BASE\") # Loading the API Base Url\n",
        "\n",
        "\n",
        "# Storing API credentials in environment variables\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "os.environ[\"OPENAI_BASE_URL\"] = OPENAI_API_BASE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Seuxx10BPYOc"
      },
      "source": [
        "#**SQL Agent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW9Oeguy0rcw"
      },
      "source": [
        "SQL agents help retrieve the product category based on the given product ID."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Working with PostgreSQL Schemas**\n",
        "\n",
        "PostgreSQL databases can have multiple schemas (like `public`, `claims`, `returns`, etc.). Here are different ways to fetch data from a specific schema:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9182bfa7",
        "outputId": "94f53f37-41f1-4082-a6cc-b9e8ed27c11c"
      },
      "outputs": [],
      "source": [
        "# Initialize the SQLDatabase object\n",
        "#db = SQLDatabase.from_uri(\"sqlite:///greatglobe.db\")\n",
        "\n",
        "# Option 1: Without schema (uses default 'public' schema)\n",
        "# db = SQLDatabase.from_uri(f\"postgresql+psycopg2://postgres:postgres@localhost:54321/postgres\")\n",
        "\n",
        "# Option 2: With specific schema (RECOMMENDED if your tables are in a non-public schema)\n",
        "db = SQLDatabase.from_uri(\n",
        "    f\"postgresql+psycopg2://postgres:postgres@localhost:54321/postgres\",\n",
        "    schema=\"claims_returns\"  # Change this to your schema name (e.g., \"claims\", \"returns\", etc.)\n",
        ")\n",
        "\n",
        "# Option 3: With multiple schemas\n",
        "# db = SQLDatabase.from_uri(\n",
        "#     f\"postgresql+psycopg2://postgres:postgres@localhost:54321/postgres\",\n",
        "#     schema=\"public,claims,returns\"  # Access multiple schemas\n",
        "# )\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) # You might need to set your OpenAI API key\n",
        "\n",
        "# Initialize a SQL agent to interact with the database using the LLM\n",
        "sql_agent = create_sql_agent(\n",
        "    llm,\n",
        "    db=db,\n",
        "    agent_type=\"openai-tools\",\n",
        "    verbose=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Alternative: Query with Schema Name in SQL**\n",
        "\n",
        "If you don't specify a schema in the connection, you can still reference specific schemas directly in your queries using the format: `schema_name.table_name`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kyC_TyYUHXuZ",
        "outputId": "406ed3b9-81d1-4d74-9561-0b985a2381c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Here are some drafts with return_type \"RETURN\":\\n\\n1. ID: 03011381-245f-487a-901f-f8f280258b0a, Date Started: 2025-02-15 00:53:45, Date Updated: 2025-02-15 00:53:45, User ID: 95d9fdf0-7ac7-4b80-bf35-902a6c1be85c\\n2. ID: bd74eaa8-fae2-46c1-b3bf-6c199e064e88, Date Started: 2025-02-25 03:40:58, Date Updated: 2025-02-25 03:40:58, User ID: 95d9fdf0-7ac7-4b80-bf35-902a6c1be85c\\n3. ID: 759ca765-c5c5-4419-9d7a-6781482e342e, Date Started: 2025-02-15 00:53:49, Date Updated: 2025-02-15 00:53:49, User ID: 95d9fdf0-7ac7-4b80-bf35-902a6c1be85c\\n4. ID: 4e833317-8f16-4e9d-8dd1-6bae805bcb5f, Date Started: 2025-02-25 01:52:01, Date Updated: 2025-02-25 01:52:01, User ID: 95d9fdf0-7ac7-4b80-bf35-902a6c1be85c\\n5. ID: 439ffa49-877c-4011-9d07-60eb8f4d71b4, Date Started: 2025-02-15 00:53:22, Date Updated: 2025-02-15 00:53:22, User ID: 95d9fdf0-7ac7-4b80-bf35-902a6c1be85c\\n\\nI can provide more examples if needed.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = f\"Fetch the draft with return_type RETURN\"\n",
        "\n",
        "\n",
        "# Execute the query using the SQL agent and store the output\n",
        "output = sql_agent.invoke(query)\n",
        "\n",
        "# Display the retrieved records\n",
        "output['output']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rru8oL0ePbAA"
      },
      "source": [
        "#**Tavily Client**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gVinKaXVq99"
      },
      "source": [
        "**Instruction:**\n",
        "To create a Tavily API key, please follow these steps:\n",
        "\n",
        "1. Click the link provided to go to the [Tavily](https://app.tavily.com/home) website.\n",
        "2. Sign in to the Tavily website.\n",
        "3. Generate a new API key for your use.\n",
        "4. Copy the API key and store it securely for use in your project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF-mgroFCGwd",
        "outputId": "5f7e5ba0-b185-4834-aefe-85e53ffa946b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Tavily Response ===\n",
            "{'query': 'List required import/export documents and accepted payment methods for customs clearance (e.g., cash, cheque, online, duty payment portal) for goods of FMCG category shipping from USA to India', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://abhyanshshipping.com/step-by-step-guide-to-customs-clearance-in-india-what-every-importer-should-know/', 'title': 'Custom Clearance in India: Step-by-Step Import Guide for 2025', 'content': '**Importing goods into India for the first time can feel overwhelming.** The customs clearance process involves multiple steps, paperwork, and compliance checks with regulations. In essence, customs clearance ensures that **all duties, taxes, and import regulations are properly followed** before you take delivery of your goods. ## **Step-by-Step Process for Import Customs Clearance in India** Below is a list of **key documents required** for import customs clearance in India, along with their purpose: Many importers engage customs brokers or clearance services to handle documentation. At **Abhyansh Shipping**, our **Custom Clearance Services in India** ensure that all paperwork and compliance requirements are handled accurately, reducing the chances of rejection or delay.', 'score': 0.64773196, 'raw_content': None}, {'url': 'https://www.infinityapp.in/blog/export-to-usa-from-india', 'title': 'Export to USA from India: A guide for exporters in 2025 - Infinity app', 'content': 'Back to blogs Export essentials # Export to USA from India: A Guide for Exporters in 2025 In this blog **Key Takeaways:** * Every exporter needs an Import Export Code (IEC) and correct HS codes, plus adherence to US regulations like FDA, USDA, and FTC to avoid shipment delays or penalties. * Indiaâ€™s strongest export categories to the USA include textiles, pharma, gems, IT hardware/software, packaged foods, and handicrafts. * Traditional SWIFT and bank wires are slow and costly. In this guide, weâ€™ll help tell you all about compliance and top export categories to costs, tariffs, and payment methods, plus insights from exporters already selling successfully in the US market. ### **Who pays what?** Key components: Textiles, gems, pharma, IT services, organic foods, and handicrafts. Recent Blogs Export essentials', 'score': 0.6388584, 'raw_content': None}, {'url': 'https://falconfreight.com/what-import-documents-required-for-customs-clearance-in-india/', 'title': 'What Import Documents Required For Customs Clearance In India,', 'content': 'Bill of Entry (Will be issued by customs only) Â· Commercial Invoice Â· Bill of Lading or Airway Bill Â· Certificate of Origin Â· Delivery Order From Shipping Line/', 'score': 0.62770075, 'raw_content': None}, {'url': 'https://www.dhl.com/discover/en-in/e-commerce-advice/shipping-guides-by-country/guide-to-shipping-from-usa-to-india', 'title': 'A Guide to Shipping From the USA to India - DHL Express IN', 'content': 'Import Export Code (IEC)4: This is a primary document necessary for commencing import-export activities. Â· Bill of Lading / Air Waybill: This', 'score': 0.5775198, 'raw_content': None}, {'url': 'https://www.indiafilings.com/learn/documents-required-import-export/', 'title': 'Documents Required for Import or Export - IndiaFilings', 'content': 'To import or export goods into India, the following mandatory documents are prescribed per the Foreign Trade Act 1992. Import Export Code (IEC).', 'score': 0.54361504, 'raw_content': None}], 'response_time': 1.79, 'request_id': 'f07bc6c0-3851-468b-a97c-51f7a2e4f8e5'}\n"
          ]
        }
      ],
      "source": [
        "# Replace with your Tavily API Key\n",
        "TAVILY_API_KEY = \"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\"\n",
        "\n",
        "# Initialize Tavily client\n",
        "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "\n",
        "# Build your query dynamically based on product and route\n",
        "query = f\"List required import/export documents and accepted payment methods for customs clearance (e.g., cash, cheque, online, duty payment portal) for goods of FMCG category shipping from USA to India\"\n",
        "\n",
        "# Call Tavily API\n",
        "try:\n",
        "    response = tavily_client.search(query)\n",
        "    print(\"=== Tavily Response ===\")\n",
        "    print(response)\n",
        "except Exception as e:\n",
        "    print(\"Error fetching data from Tavily API:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7tArt29TNNw"
      },
      "source": [
        "#**Logistic Assistant Agent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXEUYoROTZSJ"
      },
      "source": [
        "## Search Compliance Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SYTAEwNsPuXJ"
      },
      "outputs": [],
      "source": [
        "def search_compliance_info(shipment_details: str):\n",
        "    \"\"\"\n",
        "    Uses Tavily API to search for required import/export documents and payment methods.\n",
        "    \"\"\"\n",
        "    # Build the query for Tavily based on category, source, and destination\n",
        "    tavily_query = f\"required import/export documents and accepted payment methods for customs clearance for goods of following category and shipping source and dest{shipment_details}\"\n",
        "    tavily_response = tavily_client.search(tavily_query)\n",
        "    return tavily_response[\"results\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK2DeF3UY5qU"
      },
      "source": [
        "## Format Compliance Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uyQnUlCKPwkx"
      },
      "outputs": [],
      "source": [
        "def format_compliance_info(tavily_response: str):\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a logistics assistant. Read the response throughly before generating a response. understand which countries are being refered to in the response.\n",
        "    Extract structured information from the following Tavily API response.\n",
        "\n",
        "    Requirements:\n",
        "    1. List all required import/export documents clearly under \"required_documents\". Please ensure that the documents in the list are not repeated.\n",
        "    2. If there is other important information (e.g., payment modes, duty rates, obligations, restrictions, licenses, etc.),\n",
        "       list it under \"additional_information\".\n",
        "    3. If no additional information is available, do not include the field.\n",
        "\n",
        "    Tavily response:\n",
        "    {tavily_response}\n",
        "    \"\"\"\n",
        "\n",
        "    client = OpenAI()\n",
        "\n",
        "    # Assuming client (OpenAI client) is initialized elsewhere\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7oVRRhlZAMV"
      },
      "source": [
        "## Create Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "J2vyXcO-P0xA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/g6/pcgjvcld7x552nc8hh4tfy340000gp/T/ipykernel_89831/823676538.py:17: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ],
      "source": [
        "# Define tools for the agent\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search Compliance Info\",\n",
        "        func=search_compliance_info,\n",
        "        description=\"Use this tool to search for import/export compliance information using Tavily.\",\n",
        "    ),\n",
        "\n",
        "     Tool(\n",
        "        name=\"Format Compliance Info\",\n",
        "        func=format_compliance_info,\n",
        "        description=\"Use this tool to format the raw Tavily search results into a structured output. Input should be the string output from the 'Search Compliance Info' tool.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "63hf1MEQgxGB"
      },
      "outputs": [],
      "source": [
        "def Logistic_Assistant_Agent():\n",
        "    source = input(\"Enter Source Country: \")\n",
        "    destination = input(\"Enter Destination Country: \")\n",
        "    product_id = input(\"Enter Product ID: \")\n",
        "\n",
        "    sql_query = f\"Fetch the category for product id '{product_id}'\"\n",
        "    category_result = sql_agent.invoke(sql_query)\n",
        "    category = category_result['output']\n",
        "    category = category.replace(\"\", \"\")\n",
        "\n",
        "    # Pass structured input to the agent\n",
        "    agent_input = f\"Below are the details for the query Category: {category},Source: {source},Destination: {destination}\"\n",
        "    response = agent.invoke(agent_input)\n",
        "\n",
        "    print(\"Compliance Info:\")\n",
        "    print(response['output'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hVwbHU9ZIWj"
      },
      "source": [
        "#**Sample Test Case**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MFud2mHVOhK"
      },
      "source": [
        "## Test Case 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgVnyJvnDWip"
      },
      "source": [
        "- Origin : USA\n",
        "- Destinantion : Germany\n",
        "- Product ID : P1016"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viXhKr4rMr0S",
        "outputId": "a7975b54-4eef-4ca8-fbb4-ba14455400e9"
      },
      "outputs": [],
      "source": [
        "Logistic_Assistant_Agent()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdiWtzDMVnwH"
      },
      "source": [
        "## Test Case 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdDtBiKZDYni"
      },
      "source": [
        "- Origin : United Kingdom\n",
        "- Destinantion : France\n",
        "- Product ID : P1001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnvngb_RVi5x",
        "outputId": "631f6940-55cb-4099-9cc5-b33c2db15939"
      },
      "outputs": [],
      "source": [
        "Logistic_Assistant_Agent()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ7hTs3QVxyf"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1O9NGAIefcC"
      },
      "source": [
        "The proposed **Logistics Assistant Agent** offers a step forward in automating compliance checks and streamlining shipment verification for Greatglobe Logistics. By integrating structured product information from the internal SQL database with real-time compliance intelligence from external sources (via Tavily and OpenAI), the system reduces dependency on manual research and fragmented processes.\n",
        "\n",
        "From a **business impact perspective**, this solution addresses three key challenges:\n",
        "\n",
        "1. **Operational Efficiency** - Logistics managers and supply chain teams no longer need to manually search for country-specific compliance documents or duty payment methods. The assistant delivers structured, accurate, and timely information, accelerating decision-making and reducing turnaround time per shipment.\n",
        "\n",
        "2. **Error Reduction and Compliance Assurance** - Trade compliance errors can be costly, leading to shipment delays, penalties, or reputational risks. Automating document retrieval and payment obligation identification minimizes human oversight and ensures that shipments meet international regulatory requirements consistently.\n",
        "\n",
        "3. **Scalability Across Clients and Regions** - With Greatglobe handling 20â€“30 clients and over 500 products across multiple domains, the assistant is designed to scale. It adapts to different product categories and trade routes, making it a versatile tool that supports growth without proportional increases in compliance workload.\n",
        "\n",
        "Overall, the solution enables efficient management of multiple products and clients across countries, streamlining global trade operations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQvaNDqQ3BJa"
      },
      "source": [
        "<font size = 6 color=\"#4682B4\"><b> Power Ahead </font>\n",
        "___"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
