{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["InRhpRLl2f0b","1ag-GLBu2lXW","JwDJIl_w2xvG","xH6shuFX4AW5","WAt074g1IpTA","hzsSMmaXZwQw","1Jhyc_KL4XUO","nkatirx34kGH","rVyVZ2jAeR3_","j2ZxMlZXKU9h","yDtnTT7Q6wNT","N7_ycoo7BYOY"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"500a15ed9f1947f6bc5f3038ff945646":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_412ece2e536f48a58f69fae25901d850","IPY_MODEL_bf337985a45345d2b8027aa330ea1e04","IPY_MODEL_48a8eb58055d4bb68a644e4eff491e2f"],"layout":"IPY_MODEL_fd6a47074910404c9277beca3661a40b"}},"412ece2e536f48a58f69fae25901d850":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7493544a60664f51b92b516e666ec97d","placeholder":"​","style":"IPY_MODEL_8f70a3e8cf5c4106a6d622a22b03189e","value":"model.safetensors: 100%"}},"bf337985a45345d2b8027aa330ea1e04":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d86d132bd2b4eb88fffd45f7ae8b3e4","max":4125687698,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b387c68fcbf4701b0dab6d05231175c","value":4125687698}},"48a8eb58055d4bb68a644e4eff491e2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27490fd6114048cd847639eb193206d5","placeholder":"​","style":"IPY_MODEL_41dc416f65de45b083a2ae6d8e7d33b0","value":" 4.13G/4.13G [00:44&lt;00:00, 273MB/s]"}},"fd6a47074910404c9277beca3661a40b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7493544a60664f51b92b516e666ec97d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f70a3e8cf5c4106a6d622a22b03189e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d86d132bd2b4eb88fffd45f7ae8b3e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b387c68fcbf4701b0dab6d05231175c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27490fd6114048cd847639eb193206d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41dc416f65de45b083a2ae6d8e7d33b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b53fc79a6d6c41e6b6b10b9746603510":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ccd27e8b19949c697213814fb387073","IPY_MODEL_dec50f8a8cf54808b13bfc68560f2dea","IPY_MODEL_6516f097690441efa1b0cd3927152fbd"],"layout":"IPY_MODEL_f458870e54f945b39cf2fd2aeb8ffc6f"}},"3ccd27e8b19949c697213814fb387073":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19f6fcb01b2340f9a3c3fea068f68097","placeholder":"​","style":"IPY_MODEL_f3e39cf943c1422e9a4b4618e2df2990","value":"generation_config.json: 100%"}},"dec50f8a8cf54808b13bfc68560f2dea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f60eb4a192c4ed7bba63d9e03471045","max":155,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ad85b82b524431e8c2b8ef3389939d8","value":155}},"6516f097690441efa1b0cd3927152fbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62afb54a45bc4525848802872cd07cdf","placeholder":"​","style":"IPY_MODEL_982bda6261f84ba0978be356afffa8f1","value":" 155/155 [00:00&lt;00:00, 15.9kB/s]"}},"f458870e54f945b39cf2fd2aeb8ffc6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19f6fcb01b2340f9a3c3fea068f68097":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3e39cf943c1422e9a4b4618e2df2990":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f60eb4a192c4ed7bba63d9e03471045":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ad85b82b524431e8c2b8ef3389939d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62afb54a45bc4525848802872cd07cdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"982bda6261f84ba0978be356afffa8f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd8989d2515749a3906281d245aebed1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4bc27a4773e24bc9a1e56b604f85fc67","IPY_MODEL_0732d39773ed4b8caac8b8fe8fd0475a","IPY_MODEL_964c5fd4e2dd462398204acc7da79d43"],"layout":"IPY_MODEL_afceb30ed10547398a8aa7e53bbde40e"}},"4bc27a4773e24bc9a1e56b604f85fc67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14ad0f681e384391ad49222fdfdcd63d","placeholder":"​","style":"IPY_MODEL_dd79779cf0d949998aec975043711ea8","value":"tokenizer_config.json: "}},"0732d39773ed4b8caac8b8fe8fd0475a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_33d3218d40724d369ecbe913b7167cbf","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18dd53d16d534d81b93f3f70b80eccc0","value":1}},"964c5fd4e2dd462398204acc7da79d43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dff0f6370ba4d0b8f3ee95f78b917c6","placeholder":"​","style":"IPY_MODEL_76bcc072fbcc4768b9eec5df1c1b3f78","value":" 2.13k/? [00:00&lt;00:00, 119kB/s]"}},"afceb30ed10547398a8aa7e53bbde40e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14ad0f681e384391ad49222fdfdcd63d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd79779cf0d949998aec975043711ea8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33d3218d40724d369ecbe913b7167cbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"18dd53d16d534d81b93f3f70b80eccc0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4dff0f6370ba4d0b8f3ee95f78b917c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76bcc072fbcc4768b9eec5df1c1b3f78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c3ad615c855482da5f3fc23211bd830":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2336f35cb3eb45c3a7276f1e808a621c","IPY_MODEL_a71214f0775a45f98630854f9a518d0f","IPY_MODEL_b06a22ced281461ca68b065e0b1f82f1"],"layout":"IPY_MODEL_b14ca6265e084d45b16b95c4dc3ae42f"}},"2336f35cb3eb45c3a7276f1e808a621c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5c499b1267c4156977930778e8fbe50","placeholder":"​","style":"IPY_MODEL_2fcd66da9bbf4ea8a2ca62e15ff98b86","value":"tokenizer.model: 100%"}},"a71214f0775a45f98630854f9a518d0f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cfbcf5a220d4cce979bc4b6a4acfea1","max":493443,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd57b15b0eb84c81801f3129da89af31","value":493443}},"b06a22ced281461ca68b065e0b1f82f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f91ac445623c409d857f8d09652cfe5a","placeholder":"​","style":"IPY_MODEL_ad7bbdb7a2c04dce974816b2761417f4","value":" 493k/493k [00:00&lt;00:00, 1.12MB/s]"}},"b14ca6265e084d45b16b95c4dc3ae42f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5c499b1267c4156977930778e8fbe50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fcd66da9bbf4ea8a2ca62e15ff98b86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cfbcf5a220d4cce979bc4b6a4acfea1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd57b15b0eb84c81801f3129da89af31":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f91ac445623c409d857f8d09652cfe5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad7bbdb7a2c04dce974816b2761417f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d110c96e95b4408be27f9505c46edf8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4a5024f3fcb347808c2c89ec95df1941","IPY_MODEL_4853f574b0e145a79c8ed8e17eb20839","IPY_MODEL_d7cfe5ed7b0d454f9d1d317bd12b0b4a"],"layout":"IPY_MODEL_6e023852e1524bb5a80824562bd2ab63"}},"4a5024f3fcb347808c2c89ec95df1941":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03739e282e36456ca90bec231f39f9cd","placeholder":"​","style":"IPY_MODEL_af1d806e389442f68310fc152b517533","value":"special_tokens_map.json: 100%"}},"4853f574b0e145a79c8ed8e17eb20839":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbf51986ebfd4e7f84f8039069e069f2","max":438,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9aeeca45b5764599823a63a0f9f8fe05","value":438}},"d7cfe5ed7b0d454f9d1d317bd12b0b4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c345dd8a78c481b81181cfd9e262377","placeholder":"​","style":"IPY_MODEL_5a03ce01b6ad47eaa59bf9d52e92beb3","value":" 438/438 [00:00&lt;00:00, 50.7kB/s]"}},"6e023852e1524bb5a80824562bd2ab63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03739e282e36456ca90bec231f39f9cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af1d806e389442f68310fc152b517533":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbf51986ebfd4e7f84f8039069e069f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aeeca45b5764599823a63a0f9f8fe05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c345dd8a78c481b81181cfd9e262377":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a03ce01b6ad47eaa59bf9d52e92beb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"caf39f11842e4b649924633c85a0e88a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_632f65b674b4472a8db0ac4b46e38127","IPY_MODEL_6e9a5eae28554546a514b3c3eb06e6d1","IPY_MODEL_2f282e9e3608405496e129003636e83d"],"layout":"IPY_MODEL_9ec3579c88484980989760c20eefa5a3"}},"632f65b674b4472a8db0ac4b46e38127":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea55bd7d74584d63a9e384e2df0e291c","placeholder":"​","style":"IPY_MODEL_7de996f7f0cd46f190db73fbe4125d4f","value":"tokenizer.json: "}},"6e9a5eae28554546a514b3c3eb06e6d1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae8d396a47d7418f818ce31f997e7e32","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02e95a3115c244c095eb86c3caf37813","value":1}},"2f282e9e3608405496e129003636e83d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee00968ab0734b18bb532572ccef03a1","placeholder":"​","style":"IPY_MODEL_c216b3abe6024033827b2924d9e520bb","value":" 1.80M/? [00:00&lt;00:00, 48.1MB/s]"}},"9ec3579c88484980989760c20eefa5a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea55bd7d74584d63a9e384e2df0e291c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7de996f7f0cd46f190db73fbe4125d4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae8d396a47d7418f818ce31f997e7e32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"02e95a3115c244c095eb86c3caf37813":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee00968ab0734b18bb532572ccef03a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c216b3abe6024033827b2924d9e520bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5df420ad4b1a452a9c8177ae33abd054":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec31fb6ff15b43b8aae7bc3396e34c4c","IPY_MODEL_a3ed7ae4ca2b4eb8a0775a1a8583f650","IPY_MODEL_195709e45c914dff87b54a6dc71072eb"],"layout":"IPY_MODEL_6a7c4d66408545e187eb187333f093cb"}},"ec31fb6ff15b43b8aae7bc3396e34c4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b27ca96b3a54574927b6b191be48468","placeholder":"​","style":"IPY_MODEL_846ac3b3978c48748d87d1f320edd758","value":"Map: 100%"}},"a3ed7ae4ca2b4eb8a0775a1a8583f650":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_765c939718b94f1183c606299a45d3e6","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f5b9e0ca0a644bf91adf606e729adc9","value":1000}},"195709e45c914dff87b54a6dc71072eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f221454e9a0409a88adc5bded8971d7","placeholder":"​","style":"IPY_MODEL_7b2bf4b5a88c4dee8b2d12473d211837","value":" 1000/1000 [00:00&lt;00:00, 11296.42 examples/s]"}},"6a7c4d66408545e187eb187333f093cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b27ca96b3a54574927b6b191be48468":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"846ac3b3978c48748d87d1f320edd758":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"765c939718b94f1183c606299a45d3e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f5b9e0ca0a644bf91adf606e729adc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f221454e9a0409a88adc5bded8971d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b2bf4b5a88c4dee8b2d12473d211837":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a90627efec944a98d4fd0ba2e2f6627":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_abe9bc8edae144d4b206f2ad6bcc398d","IPY_MODEL_8e888fb6c11b4db0907b57ec02dc107b","IPY_MODEL_851ef505b24349e880b80123c437d2a0"],"layout":"IPY_MODEL_845847f23e8c43358656dbab3986ea35"}},"abe9bc8edae144d4b206f2ad6bcc398d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dd77ddc6620461e905d852b9840e2ba","placeholder":"​","style":"IPY_MODEL_5009cc84613a4cabbac19f7fcfb01325","value":"Map: 100%"}},"8e888fb6c11b4db0907b57ec02dc107b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a57be691dc1e4d71bff713bee47067d7","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47ec8e54813d4d08b6d99c12de95fd53","value":1000}},"851ef505b24349e880b80123c437d2a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fe5d2760e7e45688aca1f6543463609","placeholder":"​","style":"IPY_MODEL_07a9cb9f353346df85fa98d4440b0f8b","value":" 1000/1000 [00:00&lt;00:00, 11820.70 examples/s]"}},"845847f23e8c43358656dbab3986ea35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dd77ddc6620461e905d852b9840e2ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5009cc84613a4cabbac19f7fcfb01325":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a57be691dc1e4d71bff713bee47067d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47ec8e54813d4d08b6d99c12de95fd53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9fe5d2760e7e45688aca1f6543463609":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07a9cb9f353346df85fa98d4440b0f8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd72cac029ed4a049e4be4c49c96efa8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1c92153955a4818ab0a4e98e754f86b","IPY_MODEL_9a3e9376f3f44454a8287be0f305f694","IPY_MODEL_62111caf180343b9a21f967a508fccc5"],"layout":"IPY_MODEL_34d73e7988744fa7a5a01034fb40a638"}},"f1c92153955a4818ab0a4e98e754f86b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a045fa6f6524ffe97bd6b54c17cc7ff","placeholder":"​","style":"IPY_MODEL_fe763a1b405c41f18a8b357a4f17436e","value":"Unsloth: Tokenizing [&quot;text&quot;] (num_proc=6): 100%"}},"9a3e9376f3f44454a8287be0f305f694":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c0fc482d1a94317a4639b3b739c6701","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c16ff21dc92248ce8a453b3592b13029","value":1000}},"62111caf180343b9a21f967a508fccc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81b37a01473d4750a64925b157fb0a63","placeholder":"​","style":"IPY_MODEL_a579acc837014a7ebcea3e8aef51ec11","value":" 1000/1000 [00:02&lt;00:00, 602.51 examples/s]"}},"34d73e7988744fa7a5a01034fb40a638":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a045fa6f6524ffe97bd6b54c17cc7ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe763a1b405c41f18a8b357a4f17436e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c0fc482d1a94317a4639b3b739c6701":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c16ff21dc92248ce8a453b3592b13029":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"81b37a01473d4750a64925b157fb0a63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a579acc837014a7ebcea3e8aef51ec11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23ebda7fc89b4ccb829a95608afe0d0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf789ae5837c498aa54440a010030663","IPY_MODEL_5816b59268ef4492a6e0c5ef044c9e09","IPY_MODEL_9476c7d1de594a1493db93981ebf8e93"],"layout":"IPY_MODEL_17c2c055f7e44d2390b3f8932bbc744a"}},"bf789ae5837c498aa54440a010030663":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54d201994fa84420a7dcd1225552065e","placeholder":"​","style":"IPY_MODEL_494be9b0413c439f86cdb02ba076f169","value":"Unsloth: Tokenizing [&quot;text&quot;] (num_proc=6): 100%"}},"5816b59268ef4492a6e0c5ef044c9e09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f821bddf8d54f6a995935f57562bba6","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec498d2afda3413e8a5f756a2965760a","value":1000}},"9476c7d1de594a1493db93981ebf8e93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad5a15792f70453eb1b0bf217b73696e","placeholder":"​","style":"IPY_MODEL_61c236c4e996405a901285540778f417","value":" 1000/1000 [00:02&lt;00:00, 672.57 examples/s]"}},"17c2c055f7e44d2390b3f8932bbc744a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54d201994fa84420a7dcd1225552065e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"494be9b0413c439f86cdb02ba076f169":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f821bddf8d54f6a995935f57562bba6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec498d2afda3413e8a5f756a2965760a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad5a15792f70453eb1b0bf217b73696e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61c236c4e996405a901285540778f417":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"UmKLmjqmHMQM"},"source":["<center><p float=\"center\">\n","  <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e9/4_RGB_McCombs_School_Brand_Branded.png\" width=\"300\" height=\"100\"/>\n","  <img src=\"https://mma.prnewswire.com/media/1458111/Great_Learning_Logo.jpg?p=facebook\" width=\"200\" height=\"100\"/>\n","</p></center>\n","\n","<center><font size=10>Generative AI for Business Applications</center></font>\n","<center><font size=6>Fine-Tunning LLMs - Week 1</center></font>"]},{"cell_type":"markdown","metadata":{"id":"azxWym9-HMpz"},"source":["\n","<center><font size=6>Automated Quality Classification with Fine-Tuned LLMs</center></font>"]},{"cell_type":"markdown","source":["# Problem Statement"],"metadata":{"id":"InRhpRLl2f0b"}},{"cell_type":"markdown","source":["## Business Context"],"metadata":{"id":"1ag-GLBu2lXW"}},{"cell_type":"markdown","source":["In the digital age, online question-answer forums such as Stack Overflow, Quora, and Reddit are essential platforms for knowledge sharing and community engagement. These platforms host millions of queries and answers, providing users with a vast repository of information.\n","\n","Maintaining the quality of user-generated content is crucial for the success and satisfaction of these forums. High-quality content attracts more users, fosters a vibrant community, and enhances the platform's reputation. On the other hand, low-quality content can lead to user frustration, reduce engagement, and damage the forum's credibility.\n","\n","However, the quality of these contributions can vary significantly. Ensuring high-quality content while effectively managing low-quality submissions is a significant challenge that directly impacts the overall value of the forum."],"metadata":{"id":"M7anRWXW2qCf"}},{"cell_type":"markdown","source":["## Objective"],"metadata":{"id":"JwDJIl_w2xvG"}},{"cell_type":"markdown","source":["To develop and fine-tune a Large Language Model that can automatically classify user queries by quality, thereby reducing manual moderation effort and enhancing user experience on the platform."],"metadata":{"id":"sB7UuU5o2zPL"}},{"cell_type":"markdown","source":["## Data Description"],"metadata":{"id":"xH6shuFX4AW5"}},{"cell_type":"markdown","source":["The Stack Overflow QA Classification dataset contains user-submitted programming questions and their quality categories. It has two columns:\n","\n","- Query: The text of the user-submitted question.\n","\n","- Y: The category label indicating the quality of the question (e.g., high quality, low quality - edited, low quality - closed).\n","\n","The dataset is split into train, validation, and test sets to support model training, tuning, and evaluation."],"metadata":{"id":"Bp7gV2914IBW"}},{"cell_type":"markdown","source":["# Importing the necessary libraries"],"metadata":{"id":"WAt074g1IpTA"}},{"cell_type":"code","source":["!pip install --no-deps bitsandbytes accelerate xformers==0.0.32.post2 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n","!pip install sentencepiece protobuf huggingface_hub hf_transfer\n","!pip install transformers==4.51.3\n","!pip install --no-deps unsloth\n","!pip install -q datasets evaluate bert-score"],"metadata":{"id":"qa9hSbhM6MS-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759828089569,"user_tz":-330,"elapsed":58100,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}},"outputId":"0c0814ac-683c-48d6-c319-54db47a06abb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bitsandbytes\n","  Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n","Collecting xformers==0.0.32.post2\n","  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n","Collecting trl==0.15.2\n","  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (3.4.0)\n","Collecting cut_cross_entropy\n","  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n","Collecting unsloth_zoo\n","  Downloading unsloth_zoo-2025.10.1-py3-none-any.whl.metadata (31 kB)\n","Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl (60.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n","Downloading unsloth_zoo-2025.10.1-py3-none-any.whl (257 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.7/257.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xformers, unsloth_zoo, trl, cut_cross_entropy, bitsandbytes\n","Successfully installed bitsandbytes-0.48.1 cut_cross_entropy-25.1.1 trl-0.15.2 unsloth_zoo-2025.10.1 xformers-0.0.32.post2\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (5.29.5)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.35.3)\n","Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (0.1.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.19.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.10)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.8.3)\n","Collecting transformers==4.51.3\n","  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (3.19.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (0.35.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (2.32.4)\n","Collecting tokenizers<0.22,>=0.21 (from transformers==4.51.3)\n","  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.51.3) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (1.1.10)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.3) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.3) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.3) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.51.3) (2025.8.3)\n","Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.22.1\n","    Uninstalling tokenizers-0.22.1:\n","      Successfully uninstalled tokenizers-0.22.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.56.2\n","    Uninstalling transformers-4.56.2:\n","      Successfully uninstalled transformers-4.56.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","unsloth-zoo 2025.10.1 requires msgspec, which is not installed.\n","unsloth-zoo 2025.10.1 requires tyro, which is not installed.\n","unsloth-zoo 2025.10.1 requires datasets!=4.0.*,!=4.1.0,>=3.4.1, but you have datasets 4.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tokenizers-0.21.4 transformers-4.51.3\n","Collecting unsloth\n","  Downloading unsloth-2025.10.1-py3-none-any.whl.metadata (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unsloth-2025.10.1-py3-none-any.whl (317 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.2/317.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: unsloth\n","Successfully installed unsloth-2025.10.1\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["**Note**:\n","- After running the above cell, kindly restart the runtime (for Google Colab) or notebook kernel (for Jupyter Notebook), and run all cells sequentially from the next cell.\n","- On executing the above line of code, you might see a warning regarding package dependencies. This error message can be ignored as the above code ensures that all necessary libraries and their dependencies are maintained to successfully execute the code in ***this notebook***."],"metadata":{"id":"mDp-EYZH-69E"}},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","import torch\n","import evaluate\n","from tqdm import tqdm\n","import pandas as pd\n","from datasets import Dataset\n","\n","# Import modules from scikit-learn for machine learning tasks\n","from sklearn.metrics import f1_score\n","\n","from trl import SFTTrainer,SFTConfig\n","from transformers import TrainingArguments, EarlyStoppingCallback, DataCollatorForSeq2Seq\n","from unsloth import is_bfloat16_supported"],"metadata":{"id":"tgtsNS-UrQg9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Loading"],"metadata":{"id":"hzsSMmaXZwQw"}},{"cell_type":"markdown","source":["## Loading the Dataset"],"metadata":{"id":"1Jhyc_KL4XUO"}},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"18a6898c-6732-4033-b2d4-aaa63d51cb9e","id":"MDNVdg8GZwQx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["training=pd.read_csv(\"/content/stackflow_train.csv\")\n","training_dict = training.to_dict(orient='list')\n","validation=pd.read_csv(\"/content/stackflow_validate.csv\")\n","validation_dict = validation.to_dict(orient='list')\n","test=pd.read_csv(\"/content/stackflow_test.csv\")\n","testing_dict = test.to_dict(orient='list')"],"metadata":{"id":"M_-lprStZwQx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Preprocessing"],"metadata":{"id":"nkatirx34kGH"}},{"cell_type":"code","source":["train_dataset=Dataset.from_dict(training_dict)\n","validation_dataset=Dataset.from_dict(validation_dict)\n","test_dataset=Dataset.from_dict(testing_dict)"],"metadata":{"id":"6e3ENvMGdpUX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_query = [sample['query'] for sample in test_dataset]\n","test_class = [sample['Y'] for sample in test_dataset]"],"metadata":{"id":"BX8OWF6oeJXZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Evaluation of LLM before FineTuning"],"metadata":{"id":"rVyVZ2jAeR3_"}},{"cell_type":"markdown","source":["### Loading the Mistral Model"],"metadata":{"id":"7P_CKszd4-BB"}},{"cell_type":"code","source":["# Load the instruction-tuned Mistral 7B model with 4-bit quantization\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=\"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",                     # model name\n","    max_seq_length=5048,                                                        # maximum sequence length\n","    dtype=None,                                                                 # auto-select data type\n","    load_in_4bit=True                                                           # load in 4-bit for memory efficiency\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["500a15ed9f1947f6bc5f3038ff945646","412ece2e536f48a58f69fae25901d850","bf337985a45345d2b8027aa330ea1e04","48a8eb58055d4bb68a644e4eff491e2f","fd6a47074910404c9277beca3661a40b","7493544a60664f51b92b516e666ec97d","8f70a3e8cf5c4106a6d622a22b03189e","7d86d132bd2b4eb88fffd45f7ae8b3e4","7b387c68fcbf4701b0dab6d05231175c","27490fd6114048cd847639eb193206d5","41dc416f65de45b083a2ae6d8e7d33b0","b53fc79a6d6c41e6b6b10b9746603510","3ccd27e8b19949c697213814fb387073","dec50f8a8cf54808b13bfc68560f2dea","6516f097690441efa1b0cd3927152fbd","f458870e54f945b39cf2fd2aeb8ffc6f","19f6fcb01b2340f9a3c3fea068f68097","f3e39cf943c1422e9a4b4618e2df2990","1f60eb4a192c4ed7bba63d9e03471045","6ad85b82b524431e8c2b8ef3389939d8","62afb54a45bc4525848802872cd07cdf","982bda6261f84ba0978be356afffa8f1","cd8989d2515749a3906281d245aebed1","4bc27a4773e24bc9a1e56b604f85fc67","0732d39773ed4b8caac8b8fe8fd0475a","964c5fd4e2dd462398204acc7da79d43","afceb30ed10547398a8aa7e53bbde40e","14ad0f681e384391ad49222fdfdcd63d","dd79779cf0d949998aec975043711ea8","33d3218d40724d369ecbe913b7167cbf","18dd53d16d534d81b93f3f70b80eccc0","4dff0f6370ba4d0b8f3ee95f78b917c6","76bcc072fbcc4768b9eec5df1c1b3f78","0c3ad615c855482da5f3fc23211bd830","2336f35cb3eb45c3a7276f1e808a621c","a71214f0775a45f98630854f9a518d0f","b06a22ced281461ca68b065e0b1f82f1","b14ca6265e084d45b16b95c4dc3ae42f","f5c499b1267c4156977930778e8fbe50","2fcd66da9bbf4ea8a2ca62e15ff98b86","0cfbcf5a220d4cce979bc4b6a4acfea1","cd57b15b0eb84c81801f3129da89af31","f91ac445623c409d857f8d09652cfe5a","ad7bbdb7a2c04dce974816b2761417f4","0d110c96e95b4408be27f9505c46edf8","4a5024f3fcb347808c2c89ec95df1941","4853f574b0e145a79c8ed8e17eb20839","d7cfe5ed7b0d454f9d1d317bd12b0b4a","6e023852e1524bb5a80824562bd2ab63","03739e282e36456ca90bec231f39f9cd","af1d806e389442f68310fc152b517533","cbf51986ebfd4e7f84f8039069e069f2","9aeeca45b5764599823a63a0f9f8fe05","8c345dd8a78c481b81181cfd9e262377","5a03ce01b6ad47eaa59bf9d52e92beb3","caf39f11842e4b649924633c85a0e88a","632f65b674b4472a8db0ac4b46e38127","6e9a5eae28554546a514b3c3eb06e6d1","2f282e9e3608405496e129003636e83d","9ec3579c88484980989760c20eefa5a3","ea55bd7d74584d63a9e384e2df0e291c","7de996f7f0cd46f190db73fbe4125d4f","ae8d396a47d7418f818ce31f997e7e32","02e95a3115c244c095eb86c3caf37813","ee00968ab0734b18bb532572ccef03a1","c216b3abe6024033827b2924d9e520bb"]},"id":"ylMGudxQY7Om","executionInfo":{"status":"ok","timestamp":1759828310913,"user_tz":-330,"elapsed":67354,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}},"outputId":"ccee0725-5593-4391-f5f7-86abc19b3485"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.10.1: Fast Mistral patching. Transformers: 4.51.3.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/4.13G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"500a15ed9f1947f6bc5f3038ff945646"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/155 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b53fc79a6d6c41e6b6b10b9746603510"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd8989d2515749a3906281d245aebed1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c3ad615c855482da5f3fc23211bd830"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d110c96e95b4408be27f9505c46edf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caf39f11842e4b649924633c85a0e88a"}},"metadata":{}}]},{"cell_type":"markdown","source":["### Inference\n"],"metadata":{"id":"b9sW9YYntYcs"}},{"cell_type":"code","source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\""],"metadata":{"id":"izBT4r_1ZwQy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["instruction = \"\"\"You are a technical assistant. Your task is to classify the user query into **exactly one** of the following categories: LQ_EDIT, HQ, or LQ_CLOSE.\n","\n","**Instructions:**\n","1. Read the query carefully.\n","2. Output **only the category** (LQ_EDIT, HQ, or LQ_CLOSE).\n","3. Do **not** provide any explanation, reasoning, or extra text.\n","4. Always output the category in **uppercase exactly as written**.\n","\"\"\""],"metadata":{"id":"sleRGgwjeUda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_class = []"],"metadata":{"id":"lvoPgQRCeUda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for gold_dialogue in tqdm(test_query):\n","\n","    try:\n","        prompt = alpaca_prompt.format(\n","            instruction,\n","            gold_dialogue,\n","            \"\"\n","        )\n","\n","        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens=128,\n","            temperature=0,\n","            use_cache=True,\n","            pad_token_id=tokenizer.eos_token_id\n","        )\n","\n","        prediction = tokenizer.decode(\n","            outputs[0][inputs.input_ids.shape[-1]:],\n","            skip_special_tokens=True,\n","            cleanup_tokenization_spaces=True\n","        )\n","\n","        predicted_class.append(prediction)\n","\n","    except Exception as e:\n","        print(e) # log error and continue\n","        continue"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"86fe55b8-47e7-4dc9-8586-f7f7782353f4","executionInfo":{"status":"ok","timestamp":1759829484817,"user_tz":-330,"elapsed":14838,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}},"id":"srd8ftsKeUdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:14<00:00,  1.35it/s]\n"]}]},{"cell_type":"markdown","source":["### Evaluation\n"],"metadata":{"id":"kC8DIfb80ULd"}},{"cell_type":"markdown","source":["\n","**Note:** Metrics may vary between runs because this is a generative model, and its outputs can change slightly each time.\n"],"metadata":{"id":"PKg9obYn0lMk"}},{"cell_type":"code","source":["micro_f1_score = f1_score(predicted_class, test_class,average='micro')\n","print(micro_f1_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6fad684d-db83-4a16-b89b-a78f07863d64","executionInfo":{"status":"ok","timestamp":1759829589278,"user_tz":-330,"elapsed":17,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}},"id":"YrqRbCIreUdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.25\n"]}]},{"cell_type":"markdown","source":["# 2. Fine Tuning LLM"],"metadata":{"id":"j2ZxMlZXKU9h"}},{"cell_type":"markdown","source":["### Prompt Formatting"],"metadata":{"id":"NIqdC93Rhi0g"}},{"cell_type":"code","source":["# Get the end-of-sequence (EOS) token from the tokenizer\n","EOS_TOKEN = tokenizer.eos_token"],"metadata":{"id":"_TURs0KUrL9v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notice how we are adding the end-of-sequence token to the prompt i.e. we're adding a special marker at the end of the prompt to show it's finished"],"metadata":{"id":"2ZFaxW79CctT"}},{"cell_type":"code","source":["def prompt_formatter(example, prompt_template):\n","    # Instruction for the model\n","    instruction = 'You are a technical assistant. Your task is to classify the user query into **exactly one** of the following categories: LQ_EDIT, HQ, or LQ_CLOSE'\n","\n","    query = example[\"query\"]\n","    q_class = example[\"Y\"]\n","\n","    # Append EOS_TOKEN to mark the end of the sequence\n","    formatted_prompt = prompt_template.format(instruction, query, q_class) + EOS_TOKEN\n","\n","    # Return as a dictionary in the format expected by the trainer\n","    return {'text': formatted_prompt}\n"],"metadata":{"id":"v0sjC8_Y_e9j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply the prompt_formatter function to each example in the training dataset\n","# This formats dialogues and summaries into prompts suitable for model training\n","formatted_training_dataset = train_dataset.map(\n","    prompt_formatter,\n","    fn_kwargs={'prompt_template': alpaca_prompt}  # Pass the Alpaca-style prompt template\n",")\n"],"metadata":{"id":"V74wlPa7_e71","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["5df420ad4b1a452a9c8177ae33abd054","ec31fb6ff15b43b8aae7bc3396e34c4c","a3ed7ae4ca2b4eb8a0775a1a8583f650","195709e45c914dff87b54a6dc71072eb","6a7c4d66408545e187eb187333f093cb","2b27ca96b3a54574927b6b191be48468","846ac3b3978c48748d87d1f320edd758","765c939718b94f1183c606299a45d3e6","1f5b9e0ca0a644bf91adf606e729adc9","8f221454e9a0409a88adc5bded8971d7","7b2bf4b5a88c4dee8b2d12473d211837"]},"outputId":"4957fc01-315f-4e34-ae16-1cc9311d562b","executionInfo":{"status":"ok","timestamp":1759828329329,"user_tz":-330,"elapsed":52,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5df420ad4b1a452a9c8177ae33abd054"}},"metadata":{}}]},{"cell_type":"code","source":["# Apply the prompt_formatter function to each example in the validation dataset\n","# This formats dialogues and summaries into prompts suitable for model evaluation\n","formatted_validation_dataset = validation_dataset.map(\n","    prompt_formatter,\n","    fn_kwargs={'prompt_template': alpaca_prompt}  # Pass the Alpaca-style prompt template\n",")\n"],"metadata":{"id":"U2wTZleC_e2a","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["5a90627efec944a98d4fd0ba2e2f6627","abe9bc8edae144d4b206f2ad6bcc398d","8e888fb6c11b4db0907b57ec02dc107b","851ef505b24349e880b80123c437d2a0","845847f23e8c43358656dbab3986ea35","8dd77ddc6620461e905d852b9840e2ba","5009cc84613a4cabbac19f7fcfb01325","a57be691dc1e4d71bff713bee47067d7","47ec8e54813d4d08b6d99c12de95fd53","9fe5d2760e7e45688aca1f6543463609","07a9cb9f353346df85fa98d4440b0f8b"]},"outputId":"50496b0e-0b2a-4577-ef74-3d204eb9234c","executionInfo":{"status":"ok","timestamp":1759828329439,"user_tz":-330,"elapsed":92,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a90627efec944a98d4fd0ba2e2f6627"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Fine-Tuning"],"metadata":{"id":"aq6s8FXLY4-c"}},{"cell_type":"markdown","source":["We now patch in the adapter modules to the base model using the `get_peft_model` method."],"metadata":{"id":"JVpwCQuWLhSR"}},{"cell_type":"markdown","source":["We are adapting the large language model for our task using a technique called **LoRA (Low-Rank Adaptation)**. Instead of retraining the entire model (which would be very expensive), LoRA only updates a small number of parameters while keeping most of the model frozen.\n","\n","\n","* **`r`** - Rank of low-rank matrices; higher = more adaptation, typical 4-64.\n","* **`lora_alpha`** - Scaling factor for LoRA updates; higher = stronger effect, typical 8-32.\n","* **`lora_dropout`** - Dropout on LoRA layers to prevent overfitting, 0-0.3.\n","* **`target_modules`** - The specific parts of the model we allow to be updated.\n","* **`use_gradient_checkpointing`** - Save memory by recomputing activations, `True`/`False`.\n","* **`random_state`** - Seed for reproducibility, any integer.\n","\n","This step makes the model **lighter, faster, and cheaper to fine-tune**, while still learning how to summarize dialogues effectively."],"metadata":{"id":"Goth8Q4O4dCJ"}},{"cell_type":"markdown","source":["For more information, please refer to the [Unsloth](https://github.com/unslothai/unsloth) repository."],"metadata":{"id":"ja43AfZ3I8Nb"}},{"cell_type":"markdown","source":["**NOTE:** This is a LoRA model because we are only applying low-rank adapters on top of the frozen model weights. Although the base model is loaded in 4-bit precision, we are not using QLoRA’s specific quantization (NF4 + double quantization) or gradient handling required for QLoRA fine-tuning."],"metadata":{"id":"_QAbRmouJgpo"}},{"cell_type":"code","source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r=16,\n","    lora_alpha=16,\n","    lora_dropout=0,\n","    bias=\"none\",\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n","    use_gradient_checkpointing=True,\n","    random_state=42,\n","    loftq_config=None\n",")"],"metadata":{"id":"EEy477Z8ZTxy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7d9b9fa0-e68d-49b0-9750-5b251b2a1a29","executionInfo":{"status":"ok","timestamp":1759828333040,"user_tz":-330,"elapsed":3556,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2025.10.1 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}]},{"cell_type":"markdown","source":["For more information, please refer to the [Unsloth](https://github.com/unslothai/unsloth) repository."],"metadata":{"id":"U46Mcu4b6A6B"}},{"cell_type":"markdown","source":["**NOTE:** This is a LoRA model because we are only applying low-rank adapters on top of the frozen model weights. Although the base model is loaded in 4-bit precision, we are not using QLoRA’s specific quantization (NF4 + double quantization) or gradient handling required for QLoRA fine-tuning."],"metadata":{"id":"nyAYUCHo6A6C"}},{"cell_type":"code","source":["model"],"metadata":{"id":"VCS6BYy-DkTw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759828333064,"user_tz":-330,"elapsed":22,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}},"outputId":"fdadc618-dd76-4b4d-8a52-37672238e268"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): MistralForCausalLM(\n","      (model): MistralModel(\n","        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n","        (layers): ModuleList(\n","          (0-31): 32 x MistralDecoderLayer(\n","            (self_attn): MistralAttention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): MistralMLP(\n","              (gate_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=14336, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=14336, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=14336, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n","            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n","          )\n","        )\n","        (norm): MistralRMSNorm((4096,), eps=1e-05)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["Notice how LoRA adapters are attached to the layers specified during instantiation."],"metadata":{"id":"Da6_rFs77G78"}},{"cell_type":"markdown","source":["```\n","PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): MistralForCausalLM(\n","      (model): MistralModel(\n","        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n","        (layers): ModuleList(\n","          (0-31): 32 x MistralDecoderLayer(\n","            (self_attn): MistralAttention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                zzz(lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): LlamaRotaryEmbedding()\n","            )\n","            (mlp): MistralMLP(\n","              (gate_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=14336, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=14336, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Identity()\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=14336, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n","            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n","          )\n","        )\n","        (norm): MistralRMSNorm((4096,), eps=1e-05)\n","        (rotary_emb): LlamaRotaryEmbedding()\n","      )\n","      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n","    )\n","  )\n",")\n","```\n","\n"],"metadata":{"id":"9tB5eZxDp88t"}},{"cell_type":"markdown","source":["We are creating a **trainer** that will handle the fine-tuning of our model. The trainer takes care of feeding the data into the model, running the training loop, tracking progress, and saving results.\n","\n","Key points in this setup:\n","\n","* **Model & Tokenizer** - The language model and its tokenizer we are fine-tuning.\n","* **Training & Validation Data** - Split datasets so the model can learn on one set and be tested on another.\n","* **Max Sequence Length (5048)** - How much text the model can read at once.\n","* **Data Collator** - Groups the data into batches in the right format.\n","* **Batch Size & Gradient Accumulation** - Train on small pieces at a time (due to memory limits) and combine updates to act like a larger batch.\n","* **Learning Rate & Optimizer** - Control how fast the model learns and how updates are applied.\n","* **Epochs / Steps** - How long the model trains.\n","* **FP16 / BF16** - Use lower precision for faster and more memory-efficient training.\n","* **Output Directory** - Where trained model checkpoints and logs are saved.\n","\n","\n","This trainer automates the whole training process from sending data into the model to adjusting weights, logging progress, and saving results, making fine-tuning efficient and manageable.\n"],"metadata":{"id":"zMGd9Kdc5B-a"}},{"cell_type":"code","source":["trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = formatted_training_dataset,\n","    eval_dataset = formatted_validation_dataset,\n","    max_seq_length = 5048,\n","    packing = False,\n","    args = SFTConfig(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        max_steps = 60,\n","        learning_rate = 2e-7,\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","        report_to = \"none\",\n","    ),\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["fd72cac029ed4a049e4be4c49c96efa8","f1c92153955a4818ab0a4e98e754f86b","9a3e9376f3f44454a8287be0f305f694","62111caf180343b9a21f967a508fccc5","34d73e7988744fa7a5a01034fb40a638","9a045fa6f6524ffe97bd6b54c17cc7ff","fe763a1b405c41f18a8b357a4f17436e","4c0fc482d1a94317a4639b3b739c6701","c16ff21dc92248ce8a453b3592b13029","81b37a01473d4750a64925b157fb0a63","a579acc837014a7ebcea3e8aef51ec11","23ebda7fc89b4ccb829a95608afe0d0a","bf789ae5837c498aa54440a010030663","5816b59268ef4492a6e0c5ef044c9e09","9476c7d1de594a1493db93981ebf8e93","17c2c055f7e44d2390b3f8932bbc744a","54d201994fa84420a7dcd1225552065e","494be9b0413c439f86cdb02ba076f169","5f821bddf8d54f6a995935f57562bba6","ec498d2afda3413e8a5f756a2965760a","ad5a15792f70453eb1b0bf217b73696e","61c236c4e996405a901285540778f417"]},"id":"T3Rh-dnCv_1c","outputId":"41df1e59-6b80-4978-ed3c-9029ae84c417","executionInfo":{"status":"ok","timestamp":1759828338871,"user_tz":-330,"elapsed":5810,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd72cac029ed4a049e4be4c49c96efa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23ebda7fc89b4ccb829a95608afe0d0a"}},"metadata":{}}]},{"cell_type":"code","source":["training_history = trainer.train()"],"metadata":{"id":"fC89SJP6T21q","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"6aea8c02-06c1-4f3f-f02a-632b40f608c6","executionInfo":{"status":"ok","timestamp":1759829157759,"user_tz":-330,"elapsed":818887,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 1,000 | Num Epochs = 1 | Total steps = 60\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n","\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n"," \"-____-\"     Trainable parameters = 41,943,040 of 7,283,675,136 (0.58% trained)\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Will smartly offload gradients to save VRAM!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 13:19, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.912300</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.772000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.781000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>2.223300</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.463200</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.625100</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.454200</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.365700</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>2.085300</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.950000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.286600</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>1.633500</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>1.928400</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>1.958200</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>2.357300</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>1.282200</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>1.974700</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>1.788700</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>1.710500</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.191600</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>1.855200</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>1.661200</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>2.150500</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>1.920200</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>1.990000</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>1.581400</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>2.348400</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>1.858900</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>1.795300</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>1.361100</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>2.449300</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>1.591700</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>1.557500</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>2.004300</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>2.300200</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>1.983300</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>1.140200</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>1.877500</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>1.677900</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.842000</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>1.683700</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>1.551400</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>2.140100</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.856200</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>1.675700</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>1.596200</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>2.083700</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>1.818000</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>1.844200</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.019300</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>1.634400</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>1.529200</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>1.869300</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>1.663900</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>1.486100</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>1.672100</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>2.175400</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>1.910900</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>1.866300</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.183000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Saving the Trained Model"],"metadata":{"id":"dd27oqsM6ccz"}},{"cell_type":"markdown","source":["\n","We will be saving the **LoRA Parameters** of our fine-tuned model so that we can test/evaluate the model later. Since fine-tuning is an expensive process, it’s best to save these adapter files in case of crashes.\n"],"metadata":{"id":"C45mg7AjBMTr"}},{"cell_type":"markdown","source":["### Setup to enable bash commands"],"metadata":{"id":"H9EDRk6Zh-b7"}},{"cell_type":"markdown","source":["This code ensures that all file names and metadata are encoded in UTF-8, preventing errors when writing model files to disk or Google Drive."],"metadata":{"id":"HyWEau0dneNw"}},{"cell_type":"code","source":["# Setup to enable bash commands\n","import locale\n","\n","def getpreferredencoding():\n","    return \"UTF-8\"\n","\n","locale.getpreferredencoding = getpreferredencoding"],"metadata":{"id":"eTx6W39g6cc0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lora_model_name = \"classification-mistral-new\""],"metadata":{"id":"OQweHuIa6cc1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save_pretrained(lora_model_name)"],"metadata":{"id":"OBExqPLv6cc1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -lh {lora_model_name}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"eaa40b0a-678b-4798-b04a-9e7312c83874","executionInfo":{"status":"ok","timestamp":1759829158700,"user_tz":-330,"elapsed":20,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}},"id":"2BuUxxbo6cc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 161M\n","-rw-r--r-- 1 root root 1.1K Oct  7 09:25 adapter_config.json\n","-rw-r--r-- 1 root root 161M Oct  7 09:25 adapter_model.safetensors\n","-rw-r--r-- 1 root root 5.2K Oct  7 09:25 README.md\n"]}]},{"cell_type":"code","source":["# # Comment out this cell if you want to save the model to Google Drive\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# drive_model_path = \"/content/drive/MyDrive/finetuned_mistral_llm\"\n","\n","# !cp -r {lora_model_name} {drive_model_path}"],"metadata":{"id":"4OElW4Wt6pQ9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Evaluation of LLM after FineTuning"],"metadata":{"id":"yDtnTT7Q6wNT"}},{"cell_type":"markdown","source":["### Loading the Fine-tuned Mistral LLM"],"metadata":{"id":"HFqSbdOh6-CX"}},{"cell_type":"code","source":["fine_tune_model, fine_tune_tokenizer = FastLanguageModel.from_pretrained(\n","    model_name= lora_model_name,\n","    max_seq_length=2048,\n","    dtype=None,\n","    load_in_4bit=True\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd0ddfe3-93ea-4f54-d348-c2d95eacbffc","executionInfo":{"status":"ok","timestamp":1759829211421,"user_tz":-330,"elapsed":26801,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}},"id":"iB6tfwPw68Vl"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.10.1: Fast Mistral patching. Transformers: 4.51.3.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}]},{"cell_type":"markdown","source":["### Inferencing"],"metadata":{"id":"ik8gUge97Ao2"}},{"cell_type":"code","source":["predicted_class = []"],"metadata":{"id":"Mh27Dgep68Vm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for gold_dialogue in tqdm(test_query):\n","\n","    try:\n","        prompt = alpaca_prompt.format(\n","            instruction,\n","            gold_dialogue,\n","            \"\"\n","        )\n","\n","        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens=128,\n","            temperature=0,\n","            use_cache=True,\n","            pad_token_id=tokenizer.eos_token_id\n","        )\n","\n","        prediction = tokenizer.decode(\n","            outputs[0][inputs.input_ids.shape[-1]:],\n","            skip_special_tokens=True,\n","            cleanup_tokenization_spaces=True\n","        )\n","\n","        predicted_class.append(prediction)\n","\n","    except Exception as e:\n","        print(e) # log error and continue\n","        continue"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3017e0f5-1f24-4148-db74-3e1a00e508fe","executionInfo":{"status":"ok","timestamp":1759829226777,"user_tz":-330,"elapsed":15344,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}},"id":"snKQjoKy68Vm"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [00:15<00:00,  1.30it/s]\n"]}]},{"cell_type":"markdown","source":["### Evaluation"],"metadata":{"id":"JYHrOeNU7C4Q"}},{"cell_type":"code","source":["finetune_f1_score = f1_score(predicted_class, test_class,average='micro')\n","print(finetune_f1_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9d94f8bb-0756-4458-c916-d356e8e2169a","executionInfo":{"status":"ok","timestamp":1759829226830,"user_tz":-330,"elapsed":30,"user":{"displayName":"Umang Agarwal","userId":"12414299874256062416"}},"id":"Si7jhi5X68Vn"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.35\n"]}]},{"cell_type":"markdown","source":["We observed a delta of approximately 0.10 in the results before and after fine-tuning. This improvement could be further enhanced by extending the training duration, either by increasing the number of steps or epochs. However, we have limited the training to one epoch due to resource constraints, as the free GPU runtime on Google Colab may crash if the number of epochs is increased."],"metadata":{"id":"yh4WYvg1zaZD"}},{"cell_type":"markdown","source":["# Conclusion"],"metadata":{"id":"N7_ycoo7BYOY"}},{"cell_type":"markdown","source":["* The aim of this case study was to **demonstrate fine-tuning a Large Language Model (LLM) for a classification task**.\n","* We observed a **difference in results before and after fine-tuning**, showing the effectiveness of task-specific adaptation.\n","* Due to **resource constraints**, only **one epoch** was used for fine-tuning. Increasing the number of epochs could further improve model accuracy.\n","* The dataset used is a **sample subset** of a larger dataset. Using the full dataset would provide more data diversity and further enhance model performance.\n","* Overall, the case study highlights that **fine-tuning LLMs, sufficient training, and larger datasets** are key factors in improving classification accuracy."],"metadata":{"id":"LZlG_cQbBaw9"}}]}